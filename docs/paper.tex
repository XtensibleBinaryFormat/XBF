\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xurl}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{microtype}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Implementing XBF: An Efficient Self-Describing Binary Format}

\author{
	\IEEEauthorblockN{David Krauthamer}
	\IEEEauthorblockA{\textit{Electrical and Computer Engineering Department} \\
		\textit{Stevens Institute of Technology}\\
		Hoboken, USA \\
		dkrautha@pm.me}
	\and
	\IEEEauthorblockN{Dov Kruger}
	\IEEEauthorblockA{\textit{Electrical and Computer Engineering Department} \\
		\textit{Stevens Institute of Technology}\\
		Hoboken, USA \\
		dkruger@stevens.edu}
}

\maketitle

\begin{abstract}
	Do later
\end{abstract}

\begin{IEEEkeywords}
	Data format, XML, JSON, Binary data
\end{IEEEkeywords}

\section{Introduction}

On the web, data is largely interchanged in one of two formats, XML (Extensible Markup Language)\cite{xml_spec} or JSON (JavaScript Object Notation)\cite{json_spec}. These formats have two key features that have led to their popularity, human-readability and being self-describing. These features have inherent inefficiencies, which XBF (Xtensible Binary Format)\cite{xbf_spec} intends to solve through carefully chosen compromises.

\subsection{Self-Description}

A self-describing format is a format in which a recipient is not required to have a schema for the incoming data, and the names and types of the data being sent can be determined from the data itself. The following is an example of XML:

\begin{lstlisting}[language=XML]
<person>
	<name>John Jackson</name>
	<age>25</age>
</person>
\end{lstlisting}

This example represents a person object with two fields, a string name and integer age. The downside to being self-describing is wasted characters on the metadata describing the object. In this particular example, 14 characters of the 59 total characters actually contain the desired data, the rest are just describing the metadata. The best thing a format can do is minimize this overhead as much as possible, it cannot be eliminated while still being self-describing.

An additional optimization that could be made (but isn't with either of these formats) is deduplication of the metadata. Both JSON and XML include the metadata for every element sent, even if what is being sent is a homogenous list of elements that all share the same structure.

\subsection{Human Readability}

A human-readable format is one where data is encoded entirely as ASCII or UTF-8 characters, and formatted in such a way that a person could easily read or write it without the need of a machine. Human-readability brings with it two inefficiencies, the need to parse text data into a binary format that a computer understands, and additional overhead from whitespace characters.

\subsection{Enhancements Made}

With the inefficiencies of these two formats in mind, XBF seeks to improve on them through a few core design decisions:

\begin{IEEEitemize}
	\item Send data and metadata in a binary format (no longer human-readable).
	\item Remain self-describing, but have the option to not include metadata if it's already known, and deduplicate metadata whenever possible.
	\item Prioritize simplicity in the type system.
\end{IEEEitemize}

\section{Format Design}

Should this section be here / how in depth should this go? Should this mainly just be a reference to the spec / the paper written by Dov, or should more be spoken about here?

Similar to CSV (cite here?), we send a single header up front, followed by all of the data. For a primitive type there isn't much savings here, but there are massive savings with vectors and structs. With a vector the metadata is a discriminant indicating a vector is being sent, which is then follwed by the metadata for its internal type. This process continues recursively if the inner type (or any of its inner types) contains a vector or struct, ensuring that all metadata necessary to represent the data coming afterwards is received up front. The data is then sent in a single continuous block, something after this...

\section{Implementation}

The reference implementation for XBF\cite{xbf_impl} was written in Rust. Rust was chosen for the following reasons:
\begin{IEEEitemize}
	\item Rust is statically typed and compiled, and allows for similarly efficient code generation to C/C++.
	\item A powerful type system with tagged unions built in such that dynamic dispatch and virtual method tables weren't required.
	\item Control over the allocation and de-allocation of memory.
	\item Rust provides statically checked memory safety.
\end{IEEEitemize}

\subsection{Primitives}

The implementation of primitives is a tagged union of all possible primitive types, mapping the XBF type to the Rust native equivalent as shown in Table \ref{type_map}. The exceptions are the 256 bit integer types, which do not have an analog, and are instead represented by an array of four unsigned 64 bit integers.

Metadata for integers was an enumeration of the possible metadata discriminants, ranging from 0 to 16, represented as unsigned 8 bit integers.

\begin{table}[htbp]
	\caption{XBF Type Map}\label{type_map}
	\begin{center}
		\begin{tabular}{|c|c|}
			\hline
			\textbf{XBF Type} & \textbf{Rust Type}          \\
			\hline
			Boolean           & bool                        \\
			U8                & u8                          \\
			U16               & u16                         \\
			U32               & u32                         \\
			U64               & u64                         \\
			U128              & u128                        \\
			U256              & [u64; 4]                    \\
			I8                & i8                          \\
			I16               & i16                         \\
			I32               & i32                         \\
			I64               & i64                         \\
			I128              & i128                        \\
			I256              & [u64; 4]                    \\
			F32               & f32                         \\
			F64               & f64                         \\
			Bytes             & Vec\textless u8\textgreater \\
			String            & String                      \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\subsection{Vectors}

\subsection{Structs}

\section{Evaluation}

XBF was evaluated against a number of other self-describing data interchange formats.

\begin{IEEEitemize}
	\item CSV (Comma Separated Values)\cite{csv_spec}\cite{csv_parser}
	\item MessagePack\cite{msgpack_spec}\cite{msgpack_parser}
	\item CBOR (Concise Binary Object Representation)\cite{cbor_spec}\cite{cbor_parser}
	\item JSON\cite{json_parser}
	\item XML\cite{xml_parser}
\end{IEEEitemize}

The test consisted of two components, a client and a server, both written in Rust. The server downloaded a year of Sony stock data from Yahoo Finance\cite{sony_stock_data} in CSV format, and parsed it into a list of objects. Next, the original size of the CSV and a calculated value for how much memory is taken up by the parsed list was logged. Finally, the server waited for connections, and depending on the request received, serialized the list of objects into the requested format and sent it to the client. The serialized data was not cached, and the serialization was performed for each request.

The client performed the time measurement, as well as initiated connections to the server. For each data format, the client sent 100 requests to the server, and recorded the time it took from initiating the connection to receiving all the data. The average of the time for these 100 requests was then recorded, along with how large each response received was in bytes.

The server was a DigitalOcean Droplet\cite{digital_ocean} running Ubuntu 20.04.5 located in New York City. The client was a laptop running openSUSE Tumbleweed located in Hoboken, NJ.

\section{Results}

\begin{table}[htbp]
	\caption{Average Time and Bytes Read}
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Format} & \textbf{Avg Time (ms)} & \textbf{Bytes Read} \\
			\hline
			CSV             & 18.931802              & 16411               \\
			MessagePack     & 11.220957              & 15565               \\
			CBOR            & 16.957873              & 25507               \\
			JSON            & 21.912745              & 31180               \\
			XML             & 21.873043              & 43699               \\
			XBF             & 11.322245              & 14686               \\
			\hline
		\end{tabular}
	\end{center}\label{time_and_bytes}
\end{table}

\begin{table}[htbp]
	\caption{Format Overheads}
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Format} & \textbf{Overhead (bytes)} & \textbf{Percent Overhead} \\
			\hline
			CSV             & 1823                      & 11.1084                   \\
			MessagePack     & 977                       & 6.2769                    \\
			CBOR            & 10919                     & 42.8079                   \\
			JSON            & 16592                     & 53.2136                   \\
			XML             & 29111                     & 66.6171                   \\
			XBF             & 98                        & 0.6673                    \\
			\hline
		\end{tabular}
	\end{center}\label{overhead}
\end{table}

Original CSV data size recorded by the server: 17160 bytes.

Native data size recorded by the server: 14558 bytes.

\section{Discussion}

\section{Conclusion}

\bibliographystyle{IEEEtran}
\bibliography{refs}
\end{document}
